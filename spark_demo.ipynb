{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcb0d2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\shetty_sachin_kumar@lilly.com\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (3.3.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: py4j==0.10.9.5 in c:\\users\\shetty_sachin_kumar@lilly.com\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pyspark) (0.10.9.5)\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e66b6053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in c:\\users\\shetty_sachin_kumar@lilly.com\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "823cf268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "888e6484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x000001BCE9EAE9E0>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://AZURE-12NEDCU94:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>app</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1bce9eae9e0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = SparkSession.builder.appName('app').getOrCreate()\n",
    "print(session)\n",
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d13c7e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[('Finance', 20), ('Marketing', 10), ('HR', 5), ('Sales', 50), ('Support', 40)]\n",
      "[('Finance', 20), ('Marketing', 10)]\n",
      "[('Finance', 20), ('Marketing', 10), ('HR', 5), ('Sales', 50), ('Support', 40)]\n",
      "RDD Count: 5\n",
      "defaultdict(<class 'int'>, {'Finance': 1, 'Marketing': 1, 'HR': 1, 'Sales': 1, 'Support': 1})\n",
      "[('Sales', 50), ('Support', 40)]\n",
      "[('Sales', 50), ('Support', 40)]\n"
     ]
    }
   ],
   "source": [
    "dept=[(\"Finance\",20),(\"Marketing\",10),(\"HR\",5),(\"Sales\",50),(\"Support\",40)]\n",
    "rdd=session.sparkContext.parallelize(dept)\n",
    "print(type(dept))\n",
    "print(rdd.collect())\n",
    "print(rdd.take(2))\n",
    "print(rdd.collect())\n",
    "print(\"RDD Count:\", rdd.count())\n",
    "print(rdd.countByKey())\n",
    "result = (rdd.filter(lambda x: x[1] > 20).collect())\n",
    "print(result)\n",
    "rdd1 = session.sparkContext.parallelize(result)\n",
    "result2 = (rdd1.filter(lambda x: x[1] > 30).collect())\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed7662cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[_1: string, _2: bigint]\n",
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "a = rdd.toDF()\n",
    "print(a)\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e1c6eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+\n",
      "|Name     |id |\n",
      "+---------+---+\n",
      "|Finance  |20 |\n",
      "|Marketing|10 |\n",
      "|HR       |5  |\n",
      "|Sales    |50 |\n",
      "|Support  |40 |\n",
      "+---------+---+\n",
      "\n",
      "+---------+---+\n",
      "|Name     |id |\n",
      "+---------+---+\n",
      "|Marketing|10 |\n",
      "+---------+---+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, id: bigint]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.show(truncate=False)\n",
    "columns = [\"Name\", \"id\"]\n",
    "a = session.createDataFrame(data=dept,schema=columns)\n",
    "a.filter(a.id == 10).show(truncate=False)\n",
    "a.coalesce(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48f2bbed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, id: bigint]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.rdd.getNumPartitions()\n",
    "a.repartition(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b230c7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|  22|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|  38|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|  26|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|  35|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|  35|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|  54|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male|   2|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|  27|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|  14|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female|   4|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|  58|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|  20|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|  39|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|  14|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|  55|    0|    0|          248706|     16| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male|   2|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|     13| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|  31|    1|    0|          345763|     18| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "data = session.read.option('header', 'true').csv(f\"C:\\\\Users\\\\shetty_sachin_kumar@lilly.com\\\\Downloads\\\\titanic.csv\")\n",
    "data.show()\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33c2a60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",60000),\n",
    "        (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",70000),\n",
    "        (\"Robert\",\"\",\"Williams\",\"42114\",\"\",400000),\n",
    "        (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",500000),\n",
    "        (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e15c820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('James', '', 'Smith', '36636', 'M', 60000),\n",
       " ('Michael', 'Rose', '', '40288', 'M', 70000),\n",
       " ('Robert', '', 'Williams', '42114', '', 400000),\n",
       " ('Maria', 'Anne', 'Jones', '39192', 'F', 500000),\n",
       " ('Jen', 'Mary', 'Brown', '', 'F', 0)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47ce852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
